# Phi-4 think as DeepSeek-R1

I tried fine-tuning Microsoft's Phi-4 model using the open-source R1 dataset. Below, I'll share my steps with everyone. 

***Please click below pictures to see my demo video on Youtube***:
[![SLM-DS-R1-demo1](https://raw.githubusercontent.com/xinyuwei-david/david-share/refs/heads/master/IMAGES/6.webp)](https://www.youtube.com/watch?v=el7edql4Xug)

##  **Dataset Used**

I used the **`reasoning-deepseek`** subset from the `cognitivecomputations/dolphin-r1` dataset. This dataset was generated by the large model **DeepSeek-R1** and contains **30,000** training samples, focusing on reasoning and question-answering capabilities.  

**Why Choose This Dataset?** 



 Because it contains the model's reasoning process, wrapped with special `<think>` tags, which can help our model learn how to think and reason. 


**Data Preprocessing**

Before using this dataset, we need to do some preprocessing:

- **Merge Fields**: Combine the `reasoning` and `answer` fields in the dataset into a new `assistant_message`, and add it to the `messages` column. This way, our model can learn the complete question-answering and reasoning process.

- **Handle Special Tokens**: Since the data uses `<think>` tags, we need to add these special tokens to the tokenizer so that the model can correctly understand and generate them.

  **Partial Training Code Illustration:**

```
# Example code snippet for preprocessing  
from transformers import AutoTokenizer  
  
tokenizer = AutoTokenizer.from_pretrained('microsoft/phi-4')  
special_tokens = {'additional_special_tokens': ['<think>', '</think>']}  
tokenizer.add_special_tokens(special_tokens)  
```

##  

 
**Fine-tuning the Phi-4 Model**

During the fine-tuning process, I chose the **LoRA (Low-Rank Adaptation)** method. This is a parameter-efficient fine-tuning technique that allows the model to learn new capabilities without significantly increasing the number of parameters.

**Main Steps of Fine-tuning Include:**

1. **Load Model and Tokenizer**: Use `microsoft/phi-4` as the base model and load the corresponding tokenizer.

   ```
   from transformers import AutoModelForCausalLM  
   
   model = AutoModelForCausalLM.from_pretrained('microsoft/phi-4')  
   model.resize_token_embeddings(len(tokenizer))  
   ```

 

2. **Add Special Tokens to Tokenizer**: Add `<think>` and `</think>` to the tokenizer's special tokens and adjust the model's embedding layer to accommodate the new vocabulary size.



3. **Set Up LoRA Configuration**: Specify the model modules to train, such as `q_proj`, `k_proj`, `v_proj`, `o_proj`, etc.

```
from peft import LoraConfig  

lora_config = LoraConfig(  
    r=8,  
    lora_alpha=32,  
    target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj'],  
    lora_dropout=0.1,  
    bias='none',  
    task_type='CAUSAL_LM'  
)  
```

 

4. **Start Training**: Fine-tune the model using the preprocessed dataset.

```
# Training code (simplified)  
trainer = Trainer(  
    model=model,  
    train_dataset=train_dataset,  
    args=training_args,  
    data_collator=data_collator,  
)  
trainer.train()  
```

 

5. **Resource Consumption**

- **GPU Memory**: Approximately 14GB of GPU memory is needed.
- **Training Time**: It took about 2 hours on an RTX 3090.

------

 
**Model Testing**

After fine-tuning, I conducted a simple test on the model. I gave the model a question about the number of carrots eaten by rabbits to see if it could provide a reasonable reasoning process and answer.

**Result:**

```
Question: If 5 rabbits eat 3 carrots each, how many carrots are eaten in total?  
  
Assistant:  
<think>Each rabbit eats 3 carrots. There are 5 rabbits.  
Total carrots eaten = 5 rabbits * 3 carrots/rabbit = 15 carrots.</think>  
Answer: 15 carrots are eaten in total.  
```

##   The results were satisfying! The model successfully generated a reasoning process containing `<think>` tags, demonstrating a certain level of logical thinking ability. 

 
**Conclusion**

By using datasets provided by the community, we can fine-tune models like **Phi-4** on our own computers, enabling smaller models to possess certain "thinking" and reasoning abilities.