# An Guide to Microsoft Muse / WHAM World Model

At the end of 2024, Microsoft Research – Game Intelligence publicly released the weights and source code of WHAM (World & Human Action Model) and exposed fully‑hosted inference endpoints on both Azure and Hugging Face.
Given 10 context frames, WHAM is able to **simultaneously** predict the *next* game frame **and** the player’s *next* game‑pad input.

Before diving into the details, let me show a quick demo: I used the *Muse* model from the AML *Model Catalog*, predicted the next **50** frames from the image below, and turned them into a GIF.

**Original frame**

![images](https://github.com/xinyuwei-david/david-share/blob/master/Multimodal-Models/Muse-WHAM/images/1.png)

**GIF was automatically generated by my Python script from the 50 images it created.** — the temporal order looks smooth and logically consistent:

![示例GIF](https://github.com/xinyuwei-david/david-share/blob/master/Multimodal-Models/Muse-WHAM/images/dream_x4-50.gif)

The corresponding **action list** (16‑D vectors) for those 50 frames is printed by the following script:

| step | left_stick_x | left_stick_y | right_stick_x | right_stick_y | trigger_LT | trigger_RT | button_A | button_B | button_X | button_Y | dpad_up | dpad_down | dpad_left | dpad_right | skill_1 | skill_2 |
| ---- | ------------ | ------------ | ------------- | ------------- | ---------- | ---------- | -------- | -------- | -------- | -------- | ------- | --------- | --------- | ---------- | ------- | ------- |
| 1    | 0            | 0            | 1             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 10        | 6          | 5       | 5       |
| 2    | 0            | 0            | 1             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 9         | 6          | 5       | 5       |
| 3    | 0            | 0            | 1             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 9         | 7          | 5       | 5       |
| 4    | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 8         | 8          | 5       | 5       |
| 5    | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 8         | 8          | 5       | 5       |
| 6    | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 9         | 8          | 5       | 5       |
| 7    | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 9         | 8          | 5       | 5       |
| 8    | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 8         | 8          | 5       | 5       |
| 9    | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 7         | 9          | 5       | 5       |
| 10   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 6         | 10         | 5       | 5       |
| 11   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 6         | 10         | 0       | 5       |
| 12   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 8         | 9          | 3       | 4       |
| 13   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 8         | 8          | 5       | 5       |
| 14   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 8         | 8          | 5       | 5       |
| 15   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 8         | 9          | 5       | 5       |
| 16   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 7         | 9          | 5       | 5       |
| 17   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 7         | 9          | 5       | 5       |
| 18   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 7         | 9          | 5       | 5       |
| 19   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 7         | 9          | 5       | 5       |
| 20   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 6         | 10         | 5       | 5       |
| 21   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 5         | 10         | 5       | 5       |
| 22   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 5         | 10         | 5       | 5       |
| 23   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 5         | 10         | 5       | 5       |
| 24   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 5         | 10         | 5       | 5       |
| 25   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 4         | 10         | 5       | 5       |
| 26   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 4         | 10         | 5       | 5       |
| 27   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 4         | 10         | 5       | 5       |
| 28   | 0            | 0            | 0             | 0             | 0          | 0          | 1        | 0        | 0        | 0        | 0       | 0         | 4         | 9          | 5       | 5       |
| 29   | 0            | 0            | 0             | 0             | 0          | 0          | 1        | 0        | 0        | 0        | 0       | 0         | 3         | 9          | 5       | 5       |
| 30   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 3         | 9          | 8       | 6       |
| 31   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 2         | 9          | 10      | 6       |
| 32   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 2         | 8          | 5       | 5       |
| 33   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 1         | 8          | 5       | 5       |
| 34   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 2         | 9          | 5       | 5       |
| 35   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 4         | 9          | 5       | 5       |
| 36   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 6         | 10         | 5       | 5       |
| 37   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 6         | 10         | 0       | 5       |
| 38   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 6         | 10         | 0       | 5       |
| 39   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 6         | 10         | 4       | 5       |
| 40   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 7         | 9          | 5       | 5       |
| 41   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 5         | 5          | 5       | 5       |
| 42   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 5         | 5          | 5       | 5       |
| 43   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 5         | 5          | 5       | 5       |
| 44   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 5         | 5          | 5       | 5       |
| 45   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 5         | 5          | 5       | 5       |
| 46   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 5         | 5          | 5       | 5       |
| 47   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 5         | 5          | 5       | 5       |
| 48   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 5         | 5          | 5       | 5       |
| 49   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 5         | 5          | 5       | 5       |
| 50   | 1            | 0            | 0             | 0             | 0          | 0          | 0        | 0        | 0        | 0        | 0       | 0         | 5         | 10         | 1       | 7       |



## Background & Motivation

- ### Why 3‑D Games Need a World Model

  For more than two decades, game AI has relied on scripts, finite‑state machines, or hand‑crafted behavior trees. Although these approaches are stable, they struggle in the following scenarios:

  1. **Content creation** – Level designers want to *preview* interactions among different scenes and characters rapidly. In a traditional pipeline they have to write scripts and then run them inside the engine; each iteration is slow and human‑intensive.
  2. **AI training** – Reinforcement learning in 3‑D environments requires massive roll‑outs. Realistic engines such as Unity or Unreal are GPU‑heavy and hard to parallelize at scale.
  3. **Player personalization** – Automatically generating a large number of non‑critical path animations or scene states can dramatically cut art and animation costs.

  A World Model offers a decoupled solution: use a neural network to approximate the *joint distribution* of “real engine + player behavior.” As long as the model can synthesize plausible pixels and produce reasonable controls, we can “fast‑forward” simulation entirely on GPUs/TPUs, slashing development and training cost.

  ### Why We Picked *Bleeding Edge* as the Data Source

  • Technical fit – *Bleeding Edge* is a 3rd‑person 4‑v‑4 brawler; the camera is player‑centric, actions are diverse, and the dev team can legally access server replays and controller inputs.
  • Data scale – One year of logs, 27 990 unique players, ≈ 500 k matches.
  • Licensing & privacy – All replays and control signals are anonymized internally; only actions and pixels are kept—no voice, chat, or PII.



## Muse / WHAM at a Glance

| Metric                    | 200 M version | 1.6 B version |
| :------------------------ | ------------: | ------------: |
| Parameters                |     2.0 × 10⁸ |     1.6 × 10⁹ |
| ckpt size                 |        3.7 GB |       18.9 GB |
| VRAM per frame (A6000)    |        ≈ 4 GB |       ≈ 28 GB |
| Latency per frame (A6000) |         32 ms |         82 ms |
| Training GPUs             |     98 × H100 |          same |
| Training time             |        5 days |          same |

### Three Inference Modes

| Mode                | Input                                    | Output              | Typical use case                               |
| :------------------ | :--------------------------------------- | :------------------ | :--------------------------------------------- |
| **World Model**     | 10 frames + 10 actions                   | next frame          | physics / vision prediction, video compression |
| **Behavior Policy** | 10 frames                                | next action (16‑D)  | robot / NPC control                            |
| **Full Generation** | prompt of any length (frames or actions) | next frame + action | story or level material generation             |

**Highlight:** Muse’s API aligns perfectly with the RL formulation (sₜ, aₜ) → sₜ₊₁. Developers can treat Muse as a *high‑resolution environment simulator* and plug upper‑level RL or search algorithms on top with zero friction.



## Data & Training Details

### Data Pipeline

1. **Raw replays** – Server‑side 1080 p ⇒ down‑scaled to 300 × 180; FPS down‑sampled to 10 fps (trade‑off between detail and token length).
2. **Controller signals** – Read in XInput format; continuous values (sticks / triggers) kept as float, discrete buttons one‑hot encoded.
3. **Slicing** – Sliding window of “10 frames + 10 actions” to form sequences (O₀, A₀, …, O₉, A₉, O₁₀).
4. **Image discretization** – VQ‑GAN encoder maps each 300 × 180 frame to 75 × 45×(codebook = 1024) tokens; length ≈ 3 375.
5. **Sequence merge** – Interleave vision tokens with action tokens → total length ≈ 5 560.

### Training Hyper‑Parameters

```
batch_size          = 384      # tokens
optimizer           = AdamW
lr_schedule         = cosine
weight_decay        = 0.01
dropout             = 0.1
precision           = fp16     # + FlashAttention v2
loss                = CrossEntropy(next_token)   # no extra KL or weighting
augmentations       = random horizontal flip + brightness jitter
```

## Model Architecture Deep Dive

### VQ‑GAN Encoder/Decoder

• Encoder – 4‑stage down‑sampling ResNet, codebook = 1024, latent dim = 256.
• Decoder – Symmetric up‑sampling with bilinear skips.
Advantage: Compared with a vanilla CNN auto‑encoder, VQ‑GAN provides *discrete* latents, making tokenization Transformer‑friendly and reducing blue‑stripe artifacts.

### Transformer Backbone

• Type – GPT‑style *decoder‑only*.
• Depth × Width – 200 M = 16 layers × 1024 hid; 1.6 B = 48 layers × 2048.
• Positional encoding – 1‑D learned; vision and action tokens each have a dedicated slot.
• Cross‑modal fusion – All tokens are homogeneous; action tokens inside the context are attended just like image tokens, letting the model learn causality implicitly.

### Token Layout

```
O0_t0 O0_t1 … O0_tN,  A0,
O1_t0 … ON,  A1,   … , O9, A9,  <bos>
```



The model finally predicts the image tokens of **O₁₀**; if trained “dual‑head,” it simultaneously predicts **A₁₀** as well.

## 16‑Dimensional Action Space Breakdown

| idx  | name          | float range | Native meaning  | Typical effect         |
| :--: | :------------ | :---------- | :-------------- | :--------------------- |
|  1   | left_stick_x  | –1 ~ 1      | horizontal move | –1 left, 1 right       |
|  2   | left_stick_y  | –1 ~ 1      | vertical move   | –1 forward, 1 backward |
|  3   | right_stick_x | –1 ~ 1      | camera pan      | –1 CCW, 1 CW           |
|  4   | right_stick_y | –1 ~ 1      | camera tilt     | –1 up, 1 down          |
|  5   | trigger_LT    | 0 ~ 1       | aim / block     | 0.5 half‑press         |
|  6   | trigger_RT    | 0 ~ 1       | attack / shoot  | 1 full‑press           |
|  7   | button_A      | 0 / 1       | jump            |                        |
|  8   | button_B      | 0 / 1       | dodge           |                        |
|  9   | button_X      | 0 / 1       | light hit       |                        |
|  10  | button_Y      | 0 / 1       | heavy hit       |                        |
|  11  | dpad_up       | 0 / 1       | emote / shout   |                        |
|  12  | dpad_down     | 0 / 1       | skill 3         |                        |
|  13  | dpad_left     | 0 / 1       | switch weapon   |                        |
|  14  | dpad_right    | 0 / 1       | switch weapon   |                        |
|  15  | skill_1       | 0 / 1       | character skill |                        |
|  16  | skill_2       | 0 / 1       | character skill |                        |

*Mini experiment:* Set `right_stick_x = 1` while others are 0 → camera rotates clockwise at ≈ 90°/s. Set `trigger_RT = 1` → the character will likely perform a basic attack.



- ## End‑to‑End Python Script

  **Features**

  - `--steps N` on the CLI controls how many frames to generate.
  - Automatically detects the `actions` field; if missing → falls back to random actions.
  - Each frame is up‑scaled via Lanczos 4× (or optional Real‑ESRGAN).
  - Outputs raw PNGs, super‑res PNGs, GIF, and CSV.

```
(AIF) root@pythonvm:~/AIFperformance# cat call_muse_iterative_debug.py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
call_muse_iterative_debug.py  (2025‑04‑27)

Functionality
-------------
1. Command‑line flag --steps N controls the number of frames to generate (default 10)
2. Calls a Muse / WHAM endpoint; saves raw frames to raw/ and 4× super‑resolved
   frames to sr/
3. Creates an animated GIF (sr/dream_x4.gif)
4. Prints the first 2 KB of the server response; automatically captures any
   16‑dimensional action array
5. If the endpoint returns no action vector → falls back to a more diverse
   random input (sticks + buttons) to keep the scene changing

Dependencies
------------
pip install pillow imageio
(optional SR) pip install realesrgan torch
"""

import argparse
import base64
import getpass
import io
import json
import os
import random
import time
import urllib.request
from typing import List, Optional

from PIL import Image
import imageio.v3 as imageio

# ---------------------------------------------------------------------------
# Super‑resolution settings
# ---------------------------------------------------------------------------
USE_SR = False  # Set to True → requires realesrgan + torch

if USE_SR:
    try:
        from realesrgan import RealESRGAN
        import torch
        import numpy as np

        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        _sr = RealESRGAN(device, scale=4)
        _sr.load_weights("RealESRGAN_x4.pth")
        print("✅ Real‑ESRGAN 4× up‑scaling enabled.")
    except Exception as e:
        print("⚠️  Failed to initialize Real‑ESRGAN; falling back to Lanczos:", e)
        USE_SR = False


def upsample(img: Image.Image) -> Image.Image:
    """Upsample a PIL image by 4× using Real‑ESRGAN or Lanczos."""
    if USE_SR:
        import numpy as np

        return Image.fromarray(_sr.predict(np.array(img)))
    return img.resize((img.width * 4, img.height * 4), Image.Resampling.LANCZOS)


# ---------------------------------------------------------------------------
# File system constants
# ---------------------------------------------------------------------------
RAW_DIR, SR_DIR = "raw", "sr"
GIF_PATH, CSV_PATH = "sr/dream_x4.gif", "actions.csv"
PAYLOAD_PATH = "musePayload.txt"

# ---------------------------------------------------------------------------
# 16‑D action head names (for CSV output)
# ---------------------------------------------------------------------------
ACTION_HEAD = [
    "left_stick_x",
    "left_stick_y",
    "right_stick_x",
    "right_stick_y",
    "trigger_LT",
    "trigger_RT",
    "button_A",
    "button_B",
    "button_X",
    "button_Y",
    "dpad_up",
    "dpad_down",
    "dpad_left",
    "dpad_right",
    "skill_1",
    "skill_2",
]


# ---------------------------------------------------------------------------
# Helper functions
# ---------------------------------------------------------------------------
def build_headers(api_key: str):
    """Build HTTP headers for the Azure/HF endpoint."""
    return {
        "Content-Type": "application/json",
        "Accept": "application/json",
        "Authorization": "Bearer " + api_key,
    }


def fallback_action() -> List[float]:
    """
    Generate a richer random action vector:
    - Sticks sampled from [-1, 1]
    - RT pressed with 40 % probability
    - Exactly one random d‑pad key is pressed
    """
    v = [0.0] * 16
    v[0], v[1] = random.uniform(-1, 1), random.uniform(-1, 1)  # left stick
    v[2], v[3] = random.uniform(-1, 1), random.uniform(-1, 1)  # right stick
    v[5] = 1.0 if random.random() < 0.4 else 0.0  # RT
    dpad_index = 10 + random.randint(0, 3)  # choose one d‑pad key
    v[dpad_index] = 1.0
    return v


def pil_to_b64(img: Image.Image, size=(300, 180)) -> str:
    """Downscale a PIL image and return its Base64‑encoded PNG bytes."""
    buf = io.BytesIO()
    img.resize(size, Image.Resampling.LANCZOS).save(buf, format="PNG")
    return base64.b64encode(buf.getvalue()).decode()


def muse_call(payload: dict, hdr: dict, url: str):
    """Send an HTTP request to the Muse / WHAM endpoint and parse the response."""
    req = urllib.request.Request(url, json.dumps(payload).encode(), hdr)
    with urllib.request.urlopen(req) as r:
        js = json.loads(r.read().decode())

    # Debug: print first 2 KB of the response
    print("── server response (first 2 KB) ──")
    print(json.dumps(js, indent=2)[:2048], "\n────────────────────────")

    img_b64 = js["results"][0]["image"]
    img = Image.open(io.BytesIO(base64.b64decode(img_b64)))

    act, act_key = None, None
    for k, v in js["results"][0].items():
        if (
            isinstance(v, (list, tuple))
            and len(v) == 16
            and all(isinstance(x, (int, float)) for x in v)
        ):
            act, act_key = list(map(float, v)), k
            break
    return img, act, act_key, list(js["results"][0].keys())


# ---------------------------------------------------------------------------
# Main entry
# ---------------------------------------------------------------------------
def main():
    parser = argparse.ArgumentParser(
        description="Iteratively call a Muse / WHAM endpoint and build a GIF."
    )
    parser.add_argument("--steps", type=int, default=10, help="number of frames (default 10)")
    parser.add_argument("--endpoint", type=str, help="AI endpoint URL")
    parser.add_argument("--key", type=str, help="API key for the endpoint")
    args = parser.parse_args()

    # -----------------------------------------------------------------------
    # Resolve endpoint & key: CLI flag → ENV var → interactive prompt
    # -----------------------------------------------------------------------
    ENDPOINT_URL = (
        args.endpoint
        or os.getenv("MUSE_ENDPOINT_URL")
        or input("Enter ENDPOINT_URL: ").strip()
    )
    API_KEY = (
        args.key
        or os.getenv("MUSE_API_KEY")
        or getpass.getpass("Enter API_KEY (input hidden): ").strip()
    )

    # -----------------------------------------------------------------------
    # Create output folders & load initial payload
    # -----------------------------------------------------------------------
    os.makedirs(RAW_DIR, exist_ok=True)
    os.makedirs(SR_DIR, exist_ok=True)

    payload = json.load(open(PAYLOAD_PATH, "r", encoding="utf-8"))
    ctx, ctx_len = payload["input_data"]["context"], len(payload["input_data"]["context"])

    # Prepare CSV
    with open(CSV_PATH, "w", encoding="utf-8") as f:
        f.write("step," + ",".join(ACTION_HEAD) + "\n")

    headers = build_headers(API_KEY)
    total_iter = args.steps

    # -----------------------------------------------------------------------
    # Main inference loop
    # -----------------------------------------------------------------------
    for step in range(total_iter):
        print(f"\n🚀 Inference {step + 1}/{total_iter}")
        try:
            img, act, act_key, keys = muse_call(payload, headers, ENDPOINT_URL)
        except Exception as e:
            print("❌ HTTP error:", e)
            break

        if act is None:
            act = fallback_action()
            print(f"⚠️  No 16‑D action found; using random fallback (keys={keys})")
        else:
            print(f"✅ Captured action field: '{act_key}'")

        # Save the raw image
        raw_path = f"{RAW_DIR}/{step + 1:02d}.png"
        img.save(raw_path)

        # Save the 4× up‑sampled image
        upsample(img).save(f"{SR_DIR}/{step + 1:02d}_x4.png")

        # Append to CSV
        with open(CSV_PATH, "a", encoding="utf-8") as f:
            f.write(f"{step + 1}," + ",".join(map(str, act)) + "\n")

        # Update context for the next call
        if len(ctx) >= ctx_len:
            ctx.pop(0)
        ctx.append(
            {"image": pil_to_b64(img), "actions": act, "actions_output": act, "tokens": []}
        )

        # Optional sleep between calls
        if step < total_iter - 1:
            time.sleep(3)

    # -----------------------------------------------------------------------
    # Build the animated GIF
    # -----------------------------------------------------------------------
    frames = [imageio.imread(f"{SR_DIR}/{i + 1:02d}_x4.png") for i in range(step + 1)]
    imageio.imwrite(GIF_PATH, frames, duration=0.25, loop=0)
    print(f"\n🎉 Done. Generated {step + 1} frames.")
    print(f"   GIF : {GIF_PATH}")
    print(f"   CSV : {CSV_PATH}")


if __name__ == "__main__":
    main()
```

Run programme

```
python call_muse_iterative_debug.py --steps 50
```

