
==========================================================================================
架构理解：
HPA：Horizontal PodAutoscaling。

HPA基于基于CPU、内存的利用率或者custom metrics这些指标，通过replication controller, deployment 或replica set中扩展pod的副本数量。



HPA 从以下 APIs获取metrics:

metrics.k8s.io是用于正常资源使用（即cpu，mem等）。
custom.metrics.k8s.io利用一个 adapter API 用于定制化metrics。
external.metrics.k8s.io允许我们查询外部非 Kube感知监控系统



OCP4的HPA基于kube-state-metrics（OCP3是metric-server）

metric-server（或heapster）是从api-server中获取cpu、内存使用率这种监控指标，并把他们发送给存储后端，如influxdb或云厂商，他当前的核心作用是：为HPA等组件提供决策指标支持。
kube-state-metrics关注于获取k8s各种资源的最新状态，如deployment或者daemonset，之所以没有把kube-state-metrics纳入到metric-server的能力中，是因为他们的关注点本质上是不一样的。metric-server仅仅是获取、格式化现有数据，写入特定的存储，实质上是一个监控系统。而kube-state-metrics是将k8s的运行状况在内存中做了个快照，并且获取新的指标，但他没有能力导出这些指标。Prometheus不会去用metric-server中的数据，他都是自己做指标收集、集成的（Prometheus包含了metric-server的能力）。



我们查看一个HPA配置，它的功能如下：
必须将API组设置为此，监控对象是DeploymentConfig
最小副本数1
最大副本数5
要观察的指标类型-CPU，内存资源

DC中观察到的所有Pod的汇总使用情况（ targetAverageUtilization）



apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: hpa-resource-metrics-cpu
spec:
  scaleTargetRef:
    apiVersion: apps.openshift.io/v1 
    kind: DeploymentConfig
    name: hello-hpa-cpu
  minReplicas: 1 
  maxReplicas: 5 
  metrics:
  - type: Resource 
    resource:
      name: cpu
      targetAverageUtilization: 50



基于custom metrics实现HPA需要"adapter" API server，例如Prometheus adapter

支持诸如http_requests之类的指标
也可以使用 metric blocks ，例如：

CPU利用率
每秒Pod数据包 
每秒入网请求



我们看一段HPA:

监控 DC（或RC，RS等）中所有Pod的平均值，利用http请求数字。500m相当于每秒0.5个请求。

kind: HorizontalPodAutoscaler
apiVersion: autoscaling/v2beta1
metadata:
 name: hpa-custom-metrics-http
spec:
 scaleTargetRef:
   kind: DeploymentConfig
   name: hello-hpa-cpu
   apiVersion: apps.openshift.io/v1
 minReplicas: 1
 maxReplicas: 5
 metrics:
   - type: Pods
     pods:
       metricName: http_requests
       targetAverageValue: 500m


======================================================================
首先创建应用
[xiwei-redhat.com@bastion ~]$ oc new-project my-hpa

[xiwei-redhat.com@bastion ~]$  oc new-app quay.io/gpte-devops-automation/pod-autoscale-lab:rc0 --name=pod-autoscale -n my-hpa
--> Found container image 4047254 (15 months old) from quay.io for "quay.io/gpte-devops-automation/pod-autoscale-lab:rc0"

    * An image stream tag will be created as "pod-autoscale:rc0" that will track this image

--> Creating resources ...
    imagestream.image.openshift.io "pod-autoscale" created
    deployment.apps "pod-autoscale" created
    service "pod-autoscale" created
--> Success
    Application is not exposed. You can expose services to the outside world by executing one or more of the commands below:
     'oc expose svc/pod-autoscale'
    Run 'oc status' to view your app.

[xiwei-redhat.com@bastion ~]$ oc expose svc pod-autoscale
route.route.openshift.io/pod-autoscale exposed


[xiwei-redhat.com@bastion ~]$ oc get pods
NAME                             READY   STATUS    RESTARTS   AGE
pod-autoscale-55f9858b67-x8k5v   1/1     Running   0          27s



===========================================================
创建Limit Range

创建Pod Limits
Min CPU		10m
Max CPU		100m
Min Memory           5Mi
Max Memory          	750Mi

创建Container Limits
Min CPU		10m
Max CPU		100m
Min Memory	5Mi
Max Memory	750Mi
Default CPU	50m
Default Memory	100Mi



[xiwei-redhat.com@bastion ~]$ echo '---
 kind: LimitRange
 apiVersion: v1
 metadata:
   name: limits
 spec:
   limits:
   - type: Pod
     max:
       cpu: 100m
       memory: 750Mi
     min:
       cpu: 10m
       memory: 5Mi
   - type: Container
     max:
       cpu: 100m
       memory: 750Mi
     min:
       cpu: 10m
       memory: 5Mi
     default:
       cpu: 50m
       memory: 100Mi
 ' | oc create -f - -n my-hpa


limitrange/limits created

=================================
创建 HPA资源

为pod-autoscale部署创建资源HPA，以在1个和5个副本之间扩展，并设置为在CPU利用率达到60％时扩展。

[centos@lb.weixinyucluster ~]$ oc get dc
NAME            REVISION   DESIRED   CURRENT   TRIGGERED BY
pod-autoscale   1          1         1         config,image(pod-autoscale:rc0)



[xiwei-redhat.com@bastion ~]$ oc autoscale dc/pod-autoscale --min 1 --max 5 --cpu-percent=60
horizontalpodautoscaler.autoscaling/pod-autoscale autoscaled



[centos@lb.weixinyucluster ~]$ oc get hpa pod-autoscale -n my-hpa
NAME            REFERENCE                        TARGETS         MINPODS   MAXPODS   REPLICAS   AGE
pod-autoscale   DeploymentConfig/pod-autoscale   <unknown>/60%   1         5         0          6s



HPA需要几分钟的时间来收集足够的指标以显示当前状态。如果在“ TARGETS ”列中看到<unknown>，请等待30秒钟，然后重复此步骤。

 oc describe hpa pod-autoscale -n my-hpa

[centos@lb.weixinyucluster ~]$ oc rollout latest pod-autoscale -n my-hpa  (抓不到数据，所以重建)
deploymentconfig.apps.openshift.io/pod-autoscale rolled out

[xiwei-redhat.com@bastion ~]$ oc describe hpa pod-autoscale -n my-hpa
Name:                                                  pod-autoscale
Namespace:                                             my-hpa
Labels:                                                <none>
Annotations:                                           <none>
CreationTimestamp:                                     Fri, 31 Jul 2020 08:20:07 -0400
Reference:                                             Deployment/pod-autoscale
Metrics:                                               ( current / target )
  resource cpu on pods  (as a percentage of request):  49% (24m) / 60%
Min replicas:                                          1
Max replicas:                                          5
Deployment pods:                                       2 current / 2 desired
Conditions:
  Type            Status  Reason              Message
  ----            ------  ------              -------
  AbleToScale     True    ReadyForNewScale    recommended size matches current size
  ScalingActive   True    ValidMetricFound    the HPA was able to successfully calculate a replica count from cpu resource utilization (percentage of request)
  ScalingLimited  False   DesiredWithinRange  the desired count is within the acceptable range
Events:
  Type     Reason                        Age                  From                       Message
  ----     ------                        ----                 ----                       -------
  Warning  FailedComputeMetricsReplicas  16m (x12 over 19m)   horizontal-pod-autoscaler  invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: missing request for cpu
  Warning  FailedGetResourceMetric       14m (x21 over 19m)   horizontal-pod-autoscaler  missing request for cpu
  Warning  FailedGetResourceMetric       9m14s (x6 over 10m)  horizontal-pod-autoscaler  did not receive metrics for any ready pods




增加 CPU load

oc rsh -n my-hpa $(oc get ep pod-autoscale -n my-hpa -o jsonpath='{ .subsets[].addresses[0].targetRef.name }')
while true;do true;done



[xiwei-redhat.com@bastion ~]$ oc get pods
NAME                             READY   STATUS    RESTARTS   AGE
pod-autoscale-55f9858b67-qcxxv   1/1     Running   0          5m41s
pod-autoscale-55f9858b67-tqkrh   1/1     Running   0          10m


================================================================================
创建Custom HPA

部署Prometheus Operator，通过UI部署Prometheus Operator
[centos@lb.weixinyucluster ~]$ oc new-project my-prometheus

在OCP的OperatorHub中安装Prometheus Operator到my-prometheus项目中 click Operators > Installed Operators > Prometheus Operator

创建Service Monitor实例
（Watch pods based on a matchLabel selector
Be watched by a Prometheus instance based on the Service Monitor's labels）

apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: pod-autoscale
  labels:
    lab: custom-hpa
spec:
  namespaceSelector:
    matchNames:
      - my-prometheus
      - my-hpa
  selector:
    matchLabels:
      app: pod-autoscale
  endpoints:
  - port: 8080-tcp
    interval: 30s



创建Prometheus实例
apiVersion: monitoring.coreos.com/v1
kind: Prometheus
metadata:
  name: my-prometheus
  labels:
    prometheus: my-prometheus
  namespace: my-prometheus
spec:
  replicas: 2
  serviceAccountName: prometheus-k8s
  securityContext: {}
  serviceMonitorSelector:
    matchLabels:
      lab: custom-hpa

创建并查看prometheus的路由：
[centos@lb.weixinyucluster ~]$ oc expose svc prometheus-operated -n my-prometheus
route.route.openshift.io/prometheus-operated exposed

[centos@lb.weixinyucluster ~]$ oc get route prometheus-operated -o jsonpath='{.spec.host}{"\n"}' -n my-prometheus
prometheus-operated-my-prometheus.apps.weixinyucluster.bluecat.ltd

现在已经部署了ServiceMonitor和Prometheus实例，您应该能够在Prometheus UI中查询http_requests_total指标，但是没有数据。 您缺少两个关键要素：

Prometheus没有适当的RBAC权限来查询其他名称空间。
没有设置可以转换Kubernetes HPA的Prometheus指标的适配器

首先，可以通过为my-prometheus命名空间中的Prometheus使用的ServiceAccount赋予对my-hpa命名空间的适当访问权限来解决RBAC权限。
$ echo "---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: my-prometheus-hpa
  namespace: my-hpa
subjects:
  - kind: ServiceAccount
    name: prometheus-k8s
    namespace: my-prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: view" | oc create -f -

返回Prometheus用户界面，再次对http_requests_total执行查询，您应该会看到结果。 如果您没有立即看到结果，请耐心等待。
![image](https://github.com/davidsajare/david-share/blob/master/IMAGES/1.png)

Prometheus可以正常工作了，现在就可以将其连接到Kubernetes，以便HPA可以根据自定义指标进行操作。 对象列表如下：
APIService
ServiceAccount
ClusterRole - custom metrics-server-resources
ClusterRole - custom-metrics-resource-reader
ClusterRoleBinding - custom-metrics:system:auth-delegator
ClusterRoleBinding - custom-metrics-resource-reader
ClusterRoleBinding - hpa-controller-custom-metrics
RoleBinding - custom-metrics-auth-reader
Secret
ConfigMap
Deployment
Service

创建所有对象
[centos@lb.weixinyucluster ~]$ oc create -f https://raw.githubusercontent.com/redhat-gpte-devopsautomation/ocp_advanced_deployment_resources/master/ocp4_adv_deploy_lab/custom_hpa/custom_adapter_kube_objects.yaml
apiservice.apiregistration.k8s.io/v1beta1.custom.metrics.k8s.io created
serviceaccount/my-metrics-apiserver created
clusterrole.rbac.authorization.k8s.io/my-metrics-server-resources created
clusterrole.rbac.authorization.k8s.io/my-metrics-resource-reader created
clusterrolebinding.rbac.authorization.k8s.io/my-metrics:system:auth-delegator created
clusterrolebinding.rbac.authorization.k8s.io/my-metrics-resource-reader created
clusterrolebinding.rbac.authorization.k8s.io/my-hpa-controller-custom-metrics created
rolebinding.rbac.authorization.k8s.io/my-metrics-auth-reader created
secret/cm-adapter-serving-certs created
configmap/adapter-config created
deployment.apps/custom-metrics-apiserver created
service/my-metrics-apiserver created


查看API service被创建：
[centos@lb.weixinyucluster ~]$ oc get apiservice v1beta1.custom.metrics.k8s.io
NAME                            SERVICE                              AVAILABLE   AGE
v1beta1.custom.metrics.k8s.io   my-prometheus/my-metrics-apiserver   True        19s

查看API中包含pods/http指标：
[centos@lb.weixinyucluster ~]$ oc get --raw /apis/custom.metrics.k8s.io/v1beta1/ | jq -r '.resources[] | select(.name | contains("pods/http"))'
{
  "name": "pods/http_requests",
  "singularName": "",
  "namespaced": true,
  "kind": "MetricValueList",
  "verbs": [
    "get"
  ]
}


=========================================================================
验证应用的Custom HPA
[centos@lb.weixinyucluster ~]$ echo "---
 kind: HorizontalPodAutoscaler
 apiVersion: autoscaling/v2beta1
 metadata:
   name: pod-autoscale-custom
   namespace: my-hpa
 spec:
   scaleTargetRef:
     kind: DeploymentConfig
     name: pod-autoscale
     apiVersion: apps.openshift.io/v1
   minReplicas: 1
   maxReplicas: 5
   metrics:
     - type: Pods
       pods:
         metricName: http_requests
         targetAverageValue: 500m" | oc create -f -
horizontalpodautoscaler.autoscaling/pod-autoscale-custom created

为了生成负载，请打开另一个SSH终端并且运行：
[centos@lb.weixinyucluster ~]$ AUTOSCALE_ROUTE=$(oc get route pod-autoscale -n my-hpa -o jsonpath='{ .spec.host}')
[centos@lb.weixinyucluster ~]$ while true;do curl http://$AUTOSCALE_ROUTE;sleep .5;done
Hello! My name is pod-autoscale-2-pvrw8. I have served 19 requests so far.
Hello! My name is pod-autoscale-2-pvrw8. I have served 20 requests so far.
Hello! My name is pod-autoscale-2-pvrw8. I have served 21 requests so far.
Hello! My name is pod-autoscale-2-pvrw8. I have served 22 requests so far.
Hello! My name is pod-autoscale-2-pvrw8. I have served 23 requests so far.


查看hpa的状态：
[centos@lb.weixinyucluster ~]$  oc describe hpa pod-autoscale-custom -n my-hpa
Name:                       pod-autoscale-custom
Namespace:                  my-hpa
Labels:                     <none>
Annotations:                <none>
CreationTimestamp:          Fri, 31 Jul 2020 12:58:08 +0000
Reference:                  DeploymentConfig/pod-autoscale
Metrics:                    ( current / target )
  "http_requests" on pods:  2 / 500m
Min replicas:               1
Max replicas:               5
DeploymentConfig pods:      1 current / 4 desired
Conditions:
  Type            Status  Reason              Message
  ----            ------  ------              -------
  AbleToScale     True    SucceededRescale    the HPA controller was able to update the target scale to 4
  ScalingActive   True    ValidMetricFound    the HPA was able to successfully calculate a replica count from pods metric http_requests
  ScalingLimited  False   DesiredWithinRange  the desired count is within the acceptable range
Events:
  Type    Reason             Age               From                       Message
  ----    ------             ----              ----                       -------
  Normal  SuccessfulRescale  8s (x3 over 38s)  horizontal-pod-autoscaler  New size: 4; reason: pods metric http_requests above target
[centos@lb.weixinyucluster ~]$  oc describe hpa pod-autoscale-custom -n my-hpa
Name:                       pod-autoscale-custom
Namespace:                  my-hpa
Labels:                     <none>
Annotations:                <none>
CreationTimestamp:          Fri, 31 Jul 2020 12:58:08 +0000
Reference:                  DeploymentConfig/pod-autoscale
Metrics:                    ( current / target )
  "http_requests" on pods:  2 / 500m
Min replicas:               1
Max replicas:               5
DeploymentConfig pods:      1 current / 4 desired
Conditions:
  Type            Status  Reason              Message
  ----            ------  ------              -------
  AbleToScale     True    SucceededRescale    the HPA controller was able to update the target scale to 4
  ScalingActive   True    ValidMetricFound    the HPA was able to successfully calculate a replica count from pods metric http_requests
  ScalingLimited  False   DesiredWithinRange  the desired count is within the acceptable range
Events:
  Type    Reason             Age                From                       Message
  ----    ------             ----               ----                       -------
  Normal  SuccessfulRescale  12s (x3 over 42s)  horizontal-pod-autoscaler  New size: 4; reason: pods metric http_requests above target


确认pod已经扩张：
[centos@lb.weixinyucluster ~]$  oc get pods -n my-hpa
NAME                     READY   STATUS              RESTARTS   AGE
pod-autoscale-1-deploy   0/1     Completed           0          26m
pod-autoscale-2-2vrgc    0/1     ContainerCreating   0          1s
pod-autoscale-2-deploy   0/1     Completed           0          24m
pod-autoscale-2-dqdrg    0/1     ContainerCreating   0          1s
pod-autoscale-2-pvrw8    1/1     Running             0          24m
pod-autoscale-2-t52hd    0/1     ContainerCreating   0          1s


================================================
部署一个新的应用程序并设置一个自定义监视器：

使用从quay.io/gpte-devops-automation/instrumented_app:rc0中拉出的应用程序
将应用程序部署到新项目中
使用相同的Prometheus实例
探索应用程序路由的/ metrics端点处的公开指标
设置HPA以根据自定义指标（http_requests）进行扩展



[centos@lb.weixinyucluster ~]$ oc new-project my-new-hpa

[centos@lb.weixinyucluster ~]$ oc new-app quay.io/gpte-devops-automation/instrumented_app:rc0 -n my-new-hpa

[centos@lb.weixinyucluster ~]$ oc expose svc instrumentedapp -n my-new-hpa
route.route.openshift.io/instrumentedapp exposed


查看新应用程序公开的所有指标：
curl http://$(oc get route instrumentedapp -n my-new-hpa -o jsonpath='{ .spec.host}')/metrics
.....................
http_response_size_bytes{handler="api",quantile="0.5"} 0
http_response_size_bytes{handler="api",quantile="0.9"} 0
http_response_size_bytes{handler="api",quantile="0.99"} 35
http_response_size_bytes_sum{handler="api"} 1575
http_response_size_bytes_count{handler="api"} 569
http_response_size_bytes{handler="prometheus",quantile="0.5"} NaN
http_response_size_bytes{handler="prometheus",quantile="0.9"} NaN
http_response_size_bytes{handler="prometheus",quantile="0.99"} NaN
http_response_size_bytes_sum{handler="prometheus"} 0
http_response_size_bytes_count{handler="prometheus"} 0
# HELP process_cpu_seconds_total Total user and system CPU time spent in seconds.
# TYPE process_cpu_seconds_total counter
process_cpu_seconds_total 0.29
# HELP process_max_fds Maximum number of open file descriptors.
# TYPE process_max_fds gauge
process_max_fds 1.048576e+06
# HELP process_open_fds Number of open file descriptors.
# TYPE process_open_fds gauge
process_open_fds 11
# HELP process_resident_memory_bytes Resident memory size in bytes.
# TYPE process_resident_memory_bytes gauge
process_resident_memory_bytes 1.4344192e+07
# HELP process_start_time_seconds Start time of the process since unix epoch in seconds.
# TYPE process_start_time_seconds gauge
process_start_time_seconds 1.59620561392e+09
# HELP process_virtual_memory_bytes Virtual memory size in bytes.
# TYPE process_virtual_memory_bytes gauge
process_virtual_memory_bytes 3.59006208e+08
[centos@lb.weixinyucluster ~]$
[centos@lb.weixinyucluster ~]$ clear
[centos@lb.weixinyucluster ~]$ curl http://$(oc get route instrumentedapp -n my-new-hpa -o jsonpath='{ .spec.host}')/metrics
# HELP codelab_api_http_requests_in_progress The current number of API HTTP requests in progress.
# TYPE codelab_api_http_requests_in_progress gauge
codelab_api_http_requests_in_progress 1
# HELP codelab_api_request_duration_seconds A histogram of the API HTTP request durations in seconds.
# TYPE codelab_api_request_duration_seconds histogram
codelab_api_request_duration_seconds_bucket{method="GET",path="/api/bar",status="200",le="0.0001"} 0
codelab_api_request_duration_seconds_bucket{method="GET",path="/api/bar",status="200",le="0.00015000000000000001"} 0
codelab_api_request_duration_seconds_bucket{method="GET",path="/api/bar",status="200",le="0.00022500000000000002"} 0
codelab_api_request_duration_seconds_bucket{method="GET",path="/api/bar",status="200",le="0.0003375"} 0
codelab_api_request_duration_seconds_bucket{method="GET",path="/api/bar",status="200",le="0.00050625"} 0
codelab_api_request_duration_seconds_bucket{method="GET",path="/api/bar",status="200",le="0.000759375"} 0
codelab_api_request_duration_seconds_bucket{method="GET",path="/api/bar",status="200",le="0.0011390624999999999"} 0
codelab_api_request_duration_seconds_bucket{method="GET",path="/api/bar",status="200",le="0.0017085937499999998"} 0
codelab_api_request_duration_seconds_bucket{method="GET",path="/api/bar",status="200",le="0.0025628906249999996"} 0
codelab_api_request_duration_seconds_bucket{method="GET",path="/api/bar",status="200",le="0.0038443359374999994"} 0
codelab_api_request_duration_seconds_bucket{method="GET",path="/api/bar",status="200",le="0.00576650390625"} 0
codelab_api_request_duration_seconds_bucket{method="GET",path="/api/bar",status="200",le="0.008649755859375"} 0
........................................

在OCP UI创建一个新的ServiceMonitor实例
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    lab: custom-hpa
  name: my-servicemonitor
  namespace: my-prometheus
spec:
  endpoints:
    - interval: 30s
      port: 8080-tcp
  namespaceSelector:
    matchNames:
    - my-new-hpa
  selector:
    matchLabels:
      app: instrumentedapp



使Prometheus可以访问您的新项目，以便它可以开始收集指标：
echo "---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: my-new-hpa
  namespace: my-new-hpa
subjects:
  - kind: ServiceAccount
    name: prometheus-k8s
    namespace: my-prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: view" | oc create -f -

Prometheus中可以收集这个指标
http_requests_total{job="instrumentedapp"}

再次运行以下命令时，您将获得许多其他输出，这些输出由Prometheus从新应用程序公开的指标中获得：
[centos@lb.weixinyucluster ~]$ oc get --raw /apis/custom.metrics.k8s.io/v1beta1/ | jq -r '.resources[] | select(.name | contains("pods/http"))'
{
  "name": "pods/http_response_size_bytes",
  "singularName": "",
  "namespaced": true,
  "kind": "MetricValueList",
  "verbs": [
    "get"
  ]
}
{
  "name": "pods/http_requests",
  "singularName": "",
  "namespaced": true,
  "kind": "MetricValueList",
  "verbs": [
    "get"
  ]
}
{
  "name": "pods/http_request_size_bytes",
  "singularName": "",
  "namespaced": true,
  "kind": "MetricValueList",
  "verbs": [
    "get"
  ]
}
{
  "name": "pods/http_response_size_bytes_count",
  "singularName": "",
  "namespaced": true,
  "kind": "MetricValueList",
  "verbs": [
    "get"
  ]
}
{
  "name": "pods/http_request_duration_microseconds_count",
  "singularName": "",
  "namespaced": true,
  "kind": "MetricValueList",
  "verbs": [
    "get"
  ]
}
{
  "name": "pods/http_request_size_bytes_sum",
  "singularName": "",
  "namespaced": true,
  "kind": "MetricValueList",
  "verbs": [
    "get"
  ]
}
{
  "name": "pods/http_request_duration_microseconds",
  "singularName": "",
  "namespaced": true,
  "kind": "MetricValueList",
  "verbs": [
    "get"
  ]
}
{
  "name": "pods/http_request_size_bytes_count",
  "singularName": "",
  "namespaced": true,
  "kind": "MetricValueList",
  "verbs": [
    "get"
  ]
}
{
  "name": "pods/http_request_duration_microseconds_sum",
  "singularName": "",
  "namespaced": true,
  "kind": "MetricValueList",
  "verbs": [
    "get"
  ]
}
{
  "name": "pods/http_response_size_bytes_sum",
  "singularName": "",
  "namespaced": true,
  "kind": "MetricValueList",
  "verbs": [
    "get"
  ]
}

在新名称空间中为新应用程序创建新的HPA：
echo "---
kind: HorizontalPodAutoscaler
apiVersion: autoscaling/v2beta1
metadata:
  name: pod-autoscale-custom
  namespace: my-new-hpa
spec:
  scaleTargetRef:
    kind: DeploymentConfig
    name: instrumentedapp
    apiVersion: apps.openshift.io/v1
  minReplicas: 1
  maxReplicas: 5
  metrics:
    - type: Pods
      pods:
        metricName: http_requests
        targetAverageValue: 50000m" | oc create -f -

该应用程序动态生成自己的负载，因此无需人为创建任何负载。 看看您是否可以算出这是如何计算的。
[centos@lb.weixinyucluster ~]$ oc get hpa
NAME                   REFERENCE                          TARGETS     MINPODS   MAXPODS   REPLICAS   AGE
pod-autoscale-custom   DeploymentConfig/instrumentedapp   49500m/50   1         5         2          57s
[centos@lb.weixinyucluster ~]$ oc describe hpa pod-autoscale-custom
Name:                       pod-autoscale-custom
Namespace:                  my-new-hpa
Labels:                     <none>
Annotations:                <none>
CreationTimestamp:          Fri, 31 Jul 2020 14:52:17 +0000
Reference:                  DeploymentConfig/instrumentedapp
Metrics:                    ( current / target )
  "http_requests" on pods:  37081m / 50
Min replicas:               1
Max replicas:               5
DeploymentConfig pods:      2 current / 2 desired
Conditions:
  Type            Status  Reason              Message
  ----            ------  ------              -------
  AbleToScale     True    ReadyForNewScale    recommended size matches current size
  ScalingActive   True    ValidMetricFound    the HPA was able to successfully calculate a replica count from pods metric http_requests
  ScalingLimited  False   DesiredWithinRange  the desired count is within the acceptable range
Events:
  Type    Reason             Age   From                       Message
  ----    ------             ----  ----                       -------
  Normal  SuccessfulRescale  53s   horizontal-pod-autoscaler  New size: 2; reason: pods metric http_requests above target
